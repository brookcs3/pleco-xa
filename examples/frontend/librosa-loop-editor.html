<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Beats - Librosa Loop Editor (2023 Research)</title>
  <link rel="stylesheet" href="style.css">
  <style>
    .track-item {
      margin: 20px 0;
      padding: 20px;
      border: 1px solid #333;
      background: #111;
      border-radius: 8px;
    }
    
    .track-info h3 {
      margin: 0 0 10px 0;
      color: #fff;
    }
    
    .waveform-container {
      position: relative;
      margin: 15px 0;
    }
    
    .waveform {
      border: 1px solid #333;
      border-radius: 4px;
      background: #000;
      cursor: crosshair;
    }
    
    .loop-markers {
      position: absolute;
      top: 0;
      left: 0;
      pointer-events: none;
      z-index: 10;
    }
    
    .loop-marker {
      position: absolute;
      width: 2px;
      height: 100%;
      background: #ff4444;
      cursor: ew-resize;
      pointer-events: all;
    }
    
    .loop-marker.start {
      background: #44ff44;
    }
    
    .loop-marker.end {
      background: #ff4444;
    }
    
    .loop-controls {
      display: flex;
      gap: 10px;
      align-items: center;
      margin: 10px 0;
      flex-wrap: wrap;
    }
    
    .loop-controls button {
      padding: 8px 16px;
      background: #333;
      color: #fff;
      border: none;
      border-radius: 4px;
      cursor: pointer;
    }
    
    .loop-controls button:hover {
      background: #555;
    }
    
    .loop-controls button.active {
      background: #0066cc;
    }
    
    .analysis-data {
      background: #001122;
      padding: 10px;
      border-radius: 4px;
      margin: 10px 0;
      font-family: monospace;
      font-size: 12px;
    }
    
    .librosa-analysis {
      background: #220011;
      padding: 10px;
      border-radius: 4px;
      margin: 10px 0;
      font-family: monospace;
      font-size: 12px;
    }
    
    .time-display {
      background: #002200;
      padding: 5px 10px;
      border-radius: 4px;
      font-family: monospace;
      font-size: 14px;
      color: #00ff00;
    }
    
    .loop-region {
      position: absolute;
      background: rgba(0, 255, 0, 0.1);
      border: 1px solid rgba(0, 255, 0, 0.3);
      pointer-events: none;
    }
    
    .slider-container {
      margin: 10px 0;
    }
    
    .slider-container label {
      display: block;
      margin-bottom: 5px;
      color: #ccc;
    }
    
    .slider {
      width: 100%;
      margin: 5px 0;
    }
  </style>
</head>
<body>
  <div class="container">
    <h1>Beats - Librosa Loop Editor</h1>
    <p>Upload audio files and use 2023 Librosa research for advanced loop analysis and editing.</p>
    
    <div class="upload-info">
      <p><strong>Advanced Audio Analysis Features:</strong></p>
      <p>• Librosa-powered spectral analysis • RMS and peak detection • Interactive loop point editing</p>
      <p>• Real-time loop playback • Mel-spectrogram visualization • Precise timing controls</p>
    </div>
    
    <form id="uploadForm">
      <input type="file" id="fileInput" accept="audio/*" required>
      <button type="submit">Upload & Analyze with Librosa</button>
    </form>
    
    <div class="test-tracks">
      <h3>Test Tracks (Validation Benchmarks):</h3>
      <button id="testShortLoop" style="margin: 5px; padding: 8px 16px; background: #333; color: #fff; border: none; border-radius: 4px; cursor: pointer;">Test: Short Loop (Expected: 2.616s, ~91.73 BPM)</button>
      <button id="testLongTrack" style="margin: 5px; padding: 8px 16px; background: #006600; color: #fff; border: none; border-radius: 4px; cursor: pointer;">Test: Long Track (Expected: Find 2.616s segment)</button>
      <button id="testJazzyDrums" style="margin: 5px; padding: 8px 16px; background: #660066; color: #fff; border: none; border-radius: 4px; cursor: pointer;">Test: Jazz Drums (Expected: 152 BPM, 3.157s)</button>
      <button id="testDriveThrough" style="margin: 5px; padding: 8px 16px; background: #cc6600; color: #fff; border: none; border-radius: 4px; cursor: pointer;">Test: Drive Through (14s → needs compression)</button>
    </div>
    
    <div id="tracks">
      <!-- Demo tracks will be loaded here -->
    </div>
  </div>

  <script>
    // Import Librosa functions (inline to avoid module issues)
    async function loadAudioBuffer(url, context = new AudioContext()) {
      const res = await fetch(url);
      const arr = await res.arrayBuffer();
      return await context.decodeAudioData(arr);
    }

    function computeRMS(audioBuffer) {
      const channel = audioBuffer.getChannelData(0);
      let sum = 0;
      for (let i = 0; i < channel.length; i++) {
        const v = channel[i];
        sum += v * v;
      }
      return Math.sqrt(sum / channel.length);
    }

    function computePeak(audioBuffer) {
      const channel = audioBuffer.getChannelData(0);
      let max = 0;
      for (let i = 0; i < channel.length; i++) {
        const v = Math.abs(channel[i]);
        if (v > max) max = v;
      }
      return max;
    }

    async function computeSpectrum(audioBuffer, fftSize = 2048) {
      const offline = new OfflineAudioContext(1, audioBuffer.length, audioBuffer.sampleRate);
      const source = offline.createBufferSource();
      source.buffer = audioBuffer;
      const analyser = offline.createAnalyser();
      analyser.fftSize = fftSize;
      source.connect(analyser);
      analyser.connect(offline.destination);
      source.start();
      await offline.startRendering();
      const data = new Float32Array(analyser.frequencyBinCount);
      analyser.getFloatFrequencyData(data);
      return Array.from(data);
    }

    // Reference loop template for training/calibration
    let referenceLoopTemplate = null;

    // Musical timing-aware loop analysis with BPM detection and phrase boundaries
    async function librosaLoopAnalysis(audioBuffer, useReference = false) {
      console.log('Starting Musical Timing-Aware Analysis...');
      
      const audioData = audioBuffer.getChannelData(0);
      const sampleRate = audioBuffer.sampleRate;
      
      // First, detect BPM and musical timing
      const bpmData = detectBPM(audioData, sampleRate);
      const beatsPerBar = 4; // Assume 4/4 time signature
      const barDuration = (60 / bpmData.bpm) * beatsPerBar;
      
      console.log(`Detected BPM: ${bpmData.bpm.toFixed(2)}, Bar duration: ${barDuration.toFixed(3)}s`);
      
      // Basic Librosa metrics
      const rms = computeRMS(audioBuffer);
      const peak = computePeak(audioBuffer);
      const spectrum = await computeSpectrum(audioBuffer);
      
      // Always use musical boundary-aware loop detection
      const loopPoints = await musicalLoopAnalysis(audioBuffer, bpmData);
      
      // Spectral analysis for better loop detection
      const spectralCentroid = computeSpectralCentroid(audioBuffer);
      const zeroCrossingRate = computeZeroCrossingRate(audioBuffer);
      
      return {
        ...loopPoints,
        rms: rms,
        peak: peak,
        spectrum: spectrum,
        spectralCentroid: spectralCentroid,
        zeroCrossingRate: zeroCrossingRate,
        confidence: loopPoints.confidence * (1 - Math.abs(rms - 0.1)), // Adjust confidence based on RMS
        bpm: bpmData.bpm,
        barDuration: barDuration,
        musicalInfo: {
          bpm: bpmData.bpm,
          barDuration: barDuration,
          beatDuration: 60 / bpmData.bpm
        }
      };
    }

    // Create reference template from known-good loop
    async function createReferenceTemplate(audioBuffer, loopStart, loopEnd) {
      const channelData = audioBuffer.getChannelData(0);
      const sampleRate = audioBuffer.sampleRate;
      const startSample = Math.floor(loopStart * sampleRate);
      const endSample = Math.floor(loopEnd * sampleRate);
      
      // Extract the reference loop segment
      const loopSegment = channelData.slice(startSample, endSample);
      
      // Compute reference characteristics
      const template = {
        duration: loopEnd - loopStart,
        samples: loopSegment.length,
        rms: computeRMS(audioBuffer),
        peak: computePeak(audioBuffer),
        spectralCentroid: computeSpectralCentroid(audioBuffer),
        zeroCrossingRate: computeZeroCrossingRate(audioBuffer),
        segment: loopSegment,
        sampleRate: sampleRate
      };
      
      console.log('Reference template created:', template);
      return template;
    }

    // Analyze longer track using reference template
    async function analyzeWithReference(audioBuffer, template) {
      const channelData = audioBuffer.getChannelData(0);
      const sampleRate = audioBuffer.sampleRate;
      const totalSamples = channelData.length;
      
      const templateLength = template.segment.length;
      const stepSize = Math.floor(sampleRate * 0.1); // Check every 100ms
      
      console.log(`Reference analysis: scanning ${totalSamples} samples with template of ${templateLength} samples`);
      
      let bestMatch = {
        position: 0,
        correlation: -Infinity,
        confidence: 0
      };
      
      // Slide the template across the audio to find best match
      for (let pos = 0; pos < totalSamples - templateLength; pos += stepSize) {
        const segment = channelData.slice(pos, pos + templateLength);
        
        // Skip if segment is mostly silence
        const segmentRMS = Math.sqrt(segment.reduce((sum, val) => sum + val * val, 0) / segment.length);
        if (segmentRMS < template.rms * 0.3) continue;
        
        // Cross-correlation with template
        let correlation = 0;
        for (let i = 0; i < templateLength; i++) {
          correlation += segment[i] * template.segment[i];
        }
        
        correlation /= templateLength;
        
        if (correlation > bestMatch.correlation) {
          bestMatch = {
            position: pos,
            correlation: correlation,
            confidence: correlation / Math.max(template.rms, segmentRMS)
          };
        }
      }
      
      // Refine the match with precise zero-crossing
      const startSample = findZeroCrossing(channelData, bestMatch.position);
      const endSample = findZeroCrossing(channelData, bestMatch.position + templateLength);
      
      const result = {
        loopStart: startSample / sampleRate,
        loopEnd: endSample / sampleRate,
        confidence: bestMatch.confidence,
        referenceMatch: bestMatch.correlation,
        templateUsed: true
      };
      
      console.log('Reference-guided result:', result);
      return result;
    }

    function computeSpectralCentroid(audioBuffer) {
      const channelData = audioBuffer.getChannelData(0);
      const fftSize = 2048;
      let centroid = 0;
      let magnitude = 0;
      
      for (let i = 0; i < channelData.length - fftSize; i += fftSize) {
        const frame = channelData.slice(i, i + fftSize);
        const fft = computeFFT(frame);
        
        let weightedSum = 0;
        let totalMagnitude = 0;
        
        for (let j = 0; j < fft.length / 2; j++) {
          const mag = Math.sqrt(fft[j * 2] ** 2 + fft[j * 2 + 1] ** 2);
          weightedSum += j * mag;
          totalMagnitude += mag;
        }
        
        if (totalMagnitude > 0) {
          centroid += weightedSum / totalMagnitude;
          magnitude += totalMagnitude;
        }
      }
      
      return centroid / (channelData.length / fftSize) * audioBuffer.sampleRate / fftSize;
    }

    function computeZeroCrossingRate(audioBuffer) {
      const channelData = audioBuffer.getChannelData(0);
      let crossings = 0;
      
      for (let i = 1; i < channelData.length; i++) {
        if ((channelData[i] >= 0) !== (channelData[i - 1] >= 0)) {
          crossings++;
        }
      }
      
      return crossings / channelData.length;
    }

    function computeFFT(frame) {
      // Simple FFT implementation (for spectral analysis)
      const N = frame.length;
      const real = new Float32Array(N);
      const imag = new Float32Array(N);
      
      for (let i = 0; i < N; i++) {
        real[i] = frame[i];
        imag[i] = 0;
      }
      
      // Simplified FFT (normally would use a proper FFT library)
      for (let i = 0; i < N; i++) {
        for (let j = 0; j < N; j++) {
          const angle = -2 * Math.PI * i * j / N;
          real[i] += frame[j] * Math.cos(angle);
          imag[i] += frame[j] * Math.sin(angle);
        }
      }
      
      const result = new Float32Array(N * 2);
      for (let i = 0; i < N; i++) {
        result[i * 2] = real[i];
        result[i * 2 + 1] = imag[i];
      }
      
      return result;
    }

    // BPM detection for musical timing analysis
    function detectBPM(audioData, sampleRate) {
      // Simple BPM detection using autocorrelation on onset strength
      const frameSize = 2048;
      const hopSize = 512;
      const numFrames = Math.floor((audioData.length - frameSize) / hopSize);
      
      // Calculate onset strength
      const onsetStrength = [];
      for (let i = 1; i < numFrames; i++) {
        const start = i * hopSize;
        const frame = audioData.slice(start, start + frameSize);
        
        // RMS energy difference for onset detection
        const currentRMS = Math.sqrt(frame.reduce((sum, s) => sum + s * s, 0) / frameSize);
        const prevFrame = audioData.slice((i-1) * hopSize, start);
        const prevRMS = Math.sqrt(prevFrame.reduce((sum, s) => sum + s * s, 0) / frameSize);
        
        onsetStrength.push(Math.max(0, currentRMS - prevRMS));
      }
      
      // Autocorrelation to find periodic patterns
      const minBPM = 60;
      const maxBPM = 180;
      const minPeriod = Math.floor((60 / maxBPM) * sampleRate / hopSize);
      const maxPeriod = Math.floor((60 / minBPM) * sampleRate / hopSize);
      
      let bestBPM = 120; // Default
      let bestCorrelation = 0;
      
      for (let period = minPeriod; period <= maxPeriod && period < onsetStrength.length / 2; period++) {
        let correlation = 0;
        let count = 0;
        
        for (let i = 0; i < onsetStrength.length - period; i++) {
          correlation += onsetStrength[i] * onsetStrength[i + period];
          count++;
        }
        
        correlation /= count;
        
        if (correlation > bestCorrelation) {
          bestCorrelation = correlation;
          bestBPM = 60 * sampleRate / (period * hopSize);
        }
      }
      
      return {
        bpm: bestBPM,
        confidence: bestCorrelation
      };
    }
    
    // Find first non-silent region in audio
    function findAudioStart(channelData, sampleRate, threshold = 0.01) {
      const windowSize = Math.floor(sampleRate * 0.1); // 100ms windows
      
      for (let i = 0; i < channelData.length - windowSize; i += windowSize) {
        const window = channelData.slice(i, i + windowSize);
        const rms = Math.sqrt(window.reduce((sum, sample) => sum + sample * sample, 0) / windowSize);
        
        if (rms > threshold) {
          // Found audio content, back up slightly and find zero crossing
          const startSearch = Math.max(0, i - windowSize);
          return findZeroCrossing(channelData, startSearch);
        }
      }
      
      return 0; // Fallback to beginning
    }
    
    // Musical boundary-aware loop detection
    async function musicalLoopAnalysis(audioBuffer, bpmData) {
      const channelData = audioBuffer.getChannelData(0);
      const sampleRate = audioBuffer.sampleRate;
      const totalSamples = channelData.length;
      
      // Skip silence at the beginning for long tracks
      const isLongTrack = audioBuffer.duration > 15;
      const audioStartSample = isLongTrack ? findAudioStart(channelData, sampleRate) : 0;
      const audioStartTime = audioStartSample / sampleRate;
      
      console.log(`Musical Analysis: Audio starts at ${audioStartTime.toFixed(3)}s`);
      
      const beatsPerBar = 4;
      const barDuration = (60 / bpmData.bpm) * beatsPerBar;
      const beatDuration = 60 / bpmData.bpm;
      
      console.log(`Musical Analysis: Bar=${barDuration.toFixed(3)}s, Beat=${beatDuration.toFixed(3)}s`);
      
      // Test musical divisions: 1/2 bar, 1 bar, 2 bars, 4 bars
      const musicalDivisions = [0.5, 1, 2, 4, 8].map(div => div * barDuration);
      const results = [];
      
      for (const loopLength of musicalDivisions) {
        // Don't test loops longer than 12 seconds or longer than half the track
        if (loopLength > 12.0 || loopLength > audioBuffer.duration / 2) continue;
        
        const loopSamples = Math.floor(loopLength * sampleRate);
        if (audioStartSample + loopSamples * 2 > totalSamples) continue;
        
        // Extract segments starting from actual audio content, not silence
        const segment1 = applyHannWindow(channelData.slice(audioStartSample, audioStartSample + loopSamples));
        const segment2 = applyHannWindow(channelData.slice(audioStartSample + loopSamples, audioStartSample + loopSamples * 2));
        
        // Cross-correlation for similarity
        let correlation = 0;
        for (let i = 0; i < segment1.length; i++) {
          correlation += segment1[i] * segment2[i];
        }
        correlation /= segment1.length;
        
        // Find zero-crossings for clean loop boundaries, starting from audio content
        const startIndex = findZeroCrossing(channelData, audioStartSample);
        const endIndex = findZeroCrossing(channelData, audioStartSample + loopSamples);
        
        // Musical timing confidence boost
        const beatAlignment = calculateBeatAlignment(loopLength, bpmData.bpm);
        const musicalConfidence = Math.abs(correlation) * beatAlignment;
        
        results.push({
          loopStart: startIndex / sampleRate,
          loopEnd: endIndex / sampleRate,
          loopLength: loopLength,
          correlation: correlation,
          confidence: musicalConfidence,
          musicalDivision: loopLength / barDuration,
          bpm: bpmData.bpm,
          isMusicalBoundary: true
        });
        
        console.log(`Testing ${(loopLength/barDuration).toFixed(1)} bars (${loopLength.toFixed(3)}s): correlation=${correlation.toFixed(4)}, confidence=${musicalConfidence.toFixed(4)}`);
      }
      
      // Also test fine-grained analysis around promising musical divisions
      const bestMusical = results.reduce((best, curr) => 
        curr.confidence > best.confidence ? curr : best, results[0]);
      
      if (bestMusical) {
        const baseLength = bestMusical.loopLength;
        for (let offset = -0.05; offset <= 0.05; offset += 0.01) {
          const testLength = baseLength + offset;
          if (testLength <= 0) continue;
          
          const loopSamples = Math.floor(testLength * sampleRate);
          if (loopSamples * 2 > totalSamples) continue;
          
          const segment1 = applyHannWindow(channelData.slice(0, loopSamples));
          const segment2 = applyHannWindow(channelData.slice(loopSamples, loopSamples * 2));
          
          let correlation = 0;
          for (let i = 0; i < segment1.length; i++) {
            correlation += segment1[i] * segment2[i];
          }
          correlation /= segment1.length;
          
          const startIndex = findZeroCrossing(channelData, 0);
          const endIndex = findZeroCrossing(channelData, loopSamples);
          
          results.push({
            loopStart: startIndex / sampleRate,
            loopEnd: endIndex / sampleRate,
            loopLength: testLength,
            correlation: correlation,
            confidence: Math.abs(correlation) * 0.9, // Slightly lower for non-exact musical boundaries
            musicalDivision: testLength / barDuration,
            bpm: bpmData.bpm,
            isMusicalBoundary: false
          });
        }
      }
      
      // For longer tracks, add sequential loop candidates starting from the end of the best loop
      if (audioBuffer.duration > 10 && bestMusical) {
        const firstLoopEnd = bestMusical.loopEnd;
        const remainingDuration = audioBuffer.duration - firstLoopEnd;
        
        // Add sequential loops starting where the first one ends
        for (const loopLength of musicalDivisions) {
          if (loopLength > remainingDuration || loopLength > 12.0) continue;
          
          const sequentialStart = firstLoopEnd;
          const sequentialEnd = sequentialStart + loopLength;
          
          if (sequentialEnd > audioBuffer.duration) continue;
          
          const startSample = Math.floor(sequentialStart * sampleRate);
          const endSample = Math.floor(sequentialEnd * sampleRate);
          const loopSamples = endSample - startSample;
          
          // Test this sequential segment
          const segment1 = applyHannWindow(channelData.slice(startSample, endSample));
          const segment2 = applyHannWindow(channelData.slice(endSample, endSample + loopSamples));
          
          if (endSample + loopSamples > totalSamples) continue;
          
          let correlation = 0;
          for (let i = 0; i < segment1.length; i++) {
            correlation += segment1[i] * segment2[i];
          }
          correlation /= segment1.length;
          
          const beatAlignment = calculateBeatAlignment(loopLength, bpmData.bpm);
          const sequentialConfidence = Math.abs(correlation) * beatAlignment * 0.8; // Slightly lower for sequential
          
          results.push({
            loopStart: sequentialStart,
            loopEnd: sequentialEnd,
            loopLength: loopLength,
            correlation: correlation,
            confidence: sequentialConfidence,
            musicalDivision: loopLength / barDuration,
            bpm: bpmData.bpm,
            isMusicalBoundary: true,
            isSequential: true
          });
          
          console.log(`Sequential candidate: ${sequentialStart.toFixed(3)}s - ${sequentialEnd.toFixed(3)}s (${(loopLength/barDuration).toFixed(1)} bars)`);
        }
      }
      
      // Sort by confidence and return best
      results.sort((a, b) => b.confidence - a.confidence);
      
      // Smart logic: For short tracks (under 15 seconds), assume entire length is the desired loop
      const isShortTrack = audioBuffer.duration < 15;
      
      let best;
      if (isShortTrack && results.length > 0) {
        // For short tracks, prefer loops that use most/all of the track
        const fullTrackCandidate = results.find(r => 
          Math.abs(r.loopLength - audioBuffer.duration) < 0.5
        );
        
        if (fullTrackCandidate) {
          best = fullTrackCandidate;
          console.log(`Short track: Using full length ${best.loopLength.toFixed(3)}s as loop`);
        } else {
          // Create a full-track loop option
          best = {
            loopStart: 0,
            loopEnd: audioBuffer.duration,
            loopLength: audioBuffer.duration,
            correlation: 0.8,
            confidence: 0.8,
            musicalDivision: audioBuffer.duration / barDuration,
            bpm: bpmData.bpm,
            isMusicalBoundary: false,
            isFullTrack: true
          };
          console.log(`Short track: Created full-track loop ${best.loopLength.toFixed(3)}s`);
        }
      } else {
        best = results[0] || {
          loopStart: 0,
          loopEnd: Math.min(barDuration, audioBuffer.duration),
          loopLength: Math.min(barDuration, audioBuffer.duration),
          correlation: 0.5,
          confidence: 0.5,
          musicalDivision: 1,
          bpm: bpmData.bpm,
          isMusicalBoundary: true
        };
      }
      
      console.log(`Best musical loop: ${(best.musicalDivision || 1).toFixed(2)} bars (${best.loopLength.toFixed(3)}s) at ${best.bpm.toFixed(1)} BPM`);
      
      return {
        loopStart: best.loopStart,
        loopEnd: best.loopEnd,
        confidence: best.confidence,
        musicalDivision: best.musicalDivision || 1,
        bpm: best.bpm,
        allCandidates: results.slice(0, 5),
        isFullTrack: best.isFullTrack || false
      };
    }
    
    // Calculate how well a loop length aligns with musical timing
    function calculateBeatAlignment(loopLength, bpm) {
      const beatDuration = 60 / bpm;
      const beatsInLoop = loopLength / beatDuration;
      
      // Prefer whole numbers of beats, half beats, or whole bars
      const beatAlignment = 1 - Math.abs(beatsInLoop - Math.round(beatsInLoop));
      
      // Extra boost for common musical divisions (1, 2, 4, 8, 16 beats)
      const commonDivisions = [1, 2, 4, 8, 16];
      const nearestDivision = commonDivisions.reduce((prev, curr) => 
        Math.abs(curr - beatsInLoop) < Math.abs(prev - beatsInLoop) ? curr : prev);
      
      const divisionBonus = Math.max(0, 1 - Math.abs(nearestDivision - beatsInLoop) / 2);
      
      return beatAlignment * 0.7 + divisionBonus * 0.3;
    }
    
    // Original loop analysis from 2023 research (fallback)
    async function analyzeLoopPoints(audioBuffer) {
      const channelData = audioBuffer.getChannelData(0);
      const sampleRate = audioBuffer.sampleRate;
      const totalSamples = channelData.length;
      
      const window = Math.min(Math.floor(sampleRate * 0.5), Math.floor(totalSamples / 2));
      const startSlice = applyHannWindow(channelData.subarray(0, window));
      const endSlice = applyHannWindow(channelData.subarray(totalSamples - window));
      
      let bestOffset = 0;
      let bestScore = -Infinity;
      
      for (let offset = 0; offset < window; offset++) {
        let score = 0;
        for (let i = 0; i < window - offset; i++) {
          score += startSlice[i] * endSlice[i + offset];
        }
        if (score > bestScore) {
          bestScore = score;
          bestOffset = offset;
        }
      }
      
      const startIndex = findZeroCrossing(channelData, 0);
      const endIndex = findZeroCrossing(channelData, totalSamples - window + bestOffset);
      
      return {
        loopStart: startIndex / sampleRate,
        loopEnd: endIndex / sampleRate,
        confidence: bestScore / window,
        bestOffset: bestOffset,
        windowSize: window
      };
    }

    function applyHannWindow(data) {
      const windowed = new Float32Array(data.length);
      for (let i = 0; i < data.length; i++) {
        const window = 0.5 * (1 - Math.cos(2 * Math.PI * i / (data.length - 1)));
        windowed[i] = data[i] * window;
      }
      return windowed;
    }

    function findZeroCrossing(data, startIndex) {
      for (let i = startIndex; i < data.length - 1; i++) {
        if (data[i] >= 0 && data[i + 1] < 0) {
          return i;
        }
      }
      return startIndex;
    }

    // Interactive waveform editor
    class WaveformEditor {
      constructor(canvas, audioBuffer, analysis) {
        this.canvas = canvas;
        this.ctx = canvas.getContext('2d');
        this.audioBuffer = audioBuffer;
        this.analysis = analysis;
        this.loopStart = analysis.loopStart;
        this.loopEnd = analysis.loopEnd;
        this.isDragging = false;
        this.dragTarget = null;
        
        this.setupInteraction();
        this.draw();
      }
      
      setupInteraction() {
        this.canvas.addEventListener('mousedown', (e) => {
          const rect = this.canvas.getBoundingClientRect();
          const x = e.clientX - rect.left;
          const time = (x / this.canvas.width) * this.audioBuffer.duration;
          
          // Check if clicking near loop markers
          const startX = (this.loopStart / this.audioBuffer.duration) * this.canvas.width;
          const endX = (this.loopEnd / this.audioBuffer.duration) * this.canvas.width;
          
          if (Math.abs(x - startX) < 10) {
            this.isDragging = true;
            this.dragTarget = 'start';
          } else if (Math.abs(x - endX) < 10) {
            this.isDragging = true;
            this.dragTarget = 'end';
          } else {
            // Set new loop point
            if (Math.abs(x - startX) < Math.abs(x - endX)) {
              this.loopStart = time;
            } else {
              this.loopEnd = time;
            }
            this.draw();
            this.onLoopChange();
          }
        });
        
        this.canvas.addEventListener('mousemove', (e) => {
          if (this.isDragging) {
            const rect = this.canvas.getBoundingClientRect();
            const x = e.clientX - rect.left;
            const time = Math.max(0, Math.min(this.audioBuffer.duration, (x / this.canvas.width) * this.audioBuffer.duration));
            
            if (this.dragTarget === 'start') {
              this.loopStart = Math.min(time, this.loopEnd - 0.1);
            } else if (this.dragTarget === 'end') {
              this.loopEnd = Math.max(time, this.loopStart + 0.1);
            }
            
            this.draw();
            this.onLoopChange();
          }
        });
        
        this.canvas.addEventListener('mouseup', () => {
          this.isDragging = false;
          this.dragTarget = null;
        });
      }
      
      draw() {
        const data = this.audioBuffer.getChannelData(0);
        const step = Math.ceil(data.length / this.canvas.width);
        
        this.ctx.fillStyle = '#000';
        this.ctx.fillRect(0, 0, this.canvas.width, this.canvas.height);
        
        // Draw waveform
        this.ctx.strokeStyle = '#00ff00';
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        
        for (let i = 0; i < this.canvas.width; i++) {
          const slice = data.slice(i * step, (i + 1) * step);
          const min = Math.min(...slice);
          const max = Math.max(...slice);
          
          const yMin = (min + 1) * this.canvas.height / 2;
          const yMax = (max + 1) * this.canvas.height / 2;
          
          this.ctx.moveTo(i, yMin);
          this.ctx.lineTo(i, yMax);
        }
        
        this.ctx.stroke();
        
        // Draw loop region
        const startX = (this.loopStart / this.audioBuffer.duration) * this.canvas.width;
        const endX = (this.loopEnd / this.audioBuffer.duration) * this.canvas.width;
        
        this.ctx.fillStyle = 'rgba(0, 255, 0, 0.1)';
        this.ctx.fillRect(startX, 0, endX - startX, this.canvas.height);
        
        // Draw loop markers
        this.ctx.strokeStyle = '#44ff44';
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(startX, 0);
        this.ctx.lineTo(startX, this.canvas.height);
        this.ctx.stroke();
        
        this.ctx.strokeStyle = '#ff4444';
        this.ctx.beginPath();
        this.ctx.moveTo(endX, 0);
        this.ctx.lineTo(endX, this.canvas.height);
        this.ctx.stroke();
      }
      
      onLoopChange() {
        // Update display and trigger events
        const event = new CustomEvent('loopChange', {
          detail: {
            loopStart: this.loopStart,
            loopEnd: this.loopEnd,
            duration: this.loopEnd - this.loopStart
          }
        });
        this.canvas.dispatchEvent(event);
      }
    }

    // Audio time compression functions
    async function pitchBasedCompress(audioBuffer, ratio) {
      // Simple resampling - changes both pitch and tempo
      const originalSampleRate = audioBuffer.sampleRate;
      const newSampleRate = originalSampleRate * ratio;
      const newLength = Math.floor(audioBuffer.length * ratio);
      
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      const compressedBuffer = audioContext.createBuffer(
        audioBuffer.numberOfChannels,
        newLength,
        originalSampleRate // Keep original sample rate
      );
      
      for (let channel = 0; channel < audioBuffer.numberOfChannels; channel++) {
        const originalData = audioBuffer.getChannelData(channel);
        const compressedData = compressedBuffer.getChannelData(channel);
        
        // Simple linear interpolation resampling
        for (let i = 0; i < newLength; i++) {
          const sourceIndex = i / ratio;
          const index = Math.floor(sourceIndex);
          const fraction = sourceIndex - index;
          
          if (index + 1 < originalData.length) {
            compressedData[i] = originalData[index] * (1 - fraction) + originalData[index + 1] * fraction;
          } else {
            compressedData[i] = originalData[index] || 0;
          }
        }
      }
      
      return compressedBuffer;
    }
    
    async function tempoBasedCompress(audioBuffer, ratio) {
      // Placeholder for more complex pitch-preserving time stretch
      // This would require algorithms like PSOLA or phase vocoder
      console.log('Tempo-based compression not fully implemented - falling back to pitch-based');
      return await pitchBasedCompress(audioBuffer, ratio);
    }

    // Simple, reliable audio player
    class LoopPlayer {
      constructor(audioBuffer) {
        this.audioBuffer = audioBuffer;
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        this.source = null;
        this.gainNode = null;
        this.isPlaying = false;
        this.loopStart = 0;
        this.loopEnd = audioBuffer.duration;
        this.startTime = 0;
      }
      
      setLoopPoints(start, end) {
        this.loopStart = start;
        this.loopEnd = end;
      }
      
      async play() {
        this.stop();
        
        // Resume audio context if suspended (required by modern browsers)
        if (this.audioContext.state === 'suspended') {
          try {
            await this.audioContext.resume();
            console.log('Audio context resumed');
          } catch (error) {
            console.error('Failed to resume audio context:', error);
            return;
          }
        }
        
        this.source = this.audioContext.createBufferSource();
        this.gainNode = this.audioContext.createGain();
        
        this.source.buffer = this.audioBuffer;
        this.source.loop = true;
        this.source.loopStart = this.loopStart;
        this.source.loopEnd = this.loopEnd;
        
        this.source.connect(this.gainNode);
        this.gainNode.connect(this.audioContext.destination);
        this.gainNode.gain.value = 0.5;
        
        try {
          console.log(`Audio buffer duration: ${this.audioBuffer.duration}s`);
          console.log(`Audio buffer sample rate: ${this.audioBuffer.sampleRate}Hz`);
          console.log(`Loop start: ${this.loopStart}s, Loop end: ${this.loopEnd}s`);
          
          this.source.start(0, this.loopStart);
          this.isPlaying = true;
          this.startTime = this.audioContext.currentTime;
          
          console.log(`Playing loop: ${this.loopStart.toFixed(3)}s - ${this.loopEnd.toFixed(3)}s`);
          console.log(`Audio context state: ${this.audioContext.state}`);
          
          // Test if audio is actually playing
          setTimeout(() => {
            console.log(`Audio context time after 100ms: ${this.audioContext.currentTime}`);
          }, 100);
          
        } catch (error) {
          console.error('Failed to start audio:', error);
        }
      }
      
      stop() {
        if (this.source) {
          this.source.stop();
          this.source = null;
        }
        this.isPlaying = false;
      }
      
      setVolume(volume) {
        if (this.gainNode) {
          this.gainNode.gain.value = volume;
        }
      }
    }

    async function processAudioFile(file) {
      const audioContext = new (window.AudioContext || window.webkitAudioContext)();
      
      try {
        console.log('Processing with Librosa integration:', file.name);
        
        const arrayBuffer = await file.arrayBuffer();
        const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
        
        // Enhanced Librosa analysis
        const analysis = await librosaLoopAnalysis(audioBuffer);
        
        const url = URL.createObjectURL(file);
        
        const track = {
          url: url,
          filename: file.name,
          duration: audioBuffer.duration,
          sampleRate: audioBuffer.sampleRate,
          channels: audioBuffer.numberOfChannels,
          buffer: audioBuffer,
          analysis: analysis
        };
        
        console.log('Librosa analysis complete:', track);
        return track;
        
      } catch (error) {
        console.error('Librosa processing error:', error);
        throw error;
      }
    }

    function createAdvancedTrackElement(track) {
      const container = document.createElement('div');
      container.className = 'track-item';
      
      const info = document.createElement('div');
      info.className = 'track-info';
      // Calculate precise timing information
      const totalSamples = track.buffer.length;
      const exactDuration = totalSamples / track.sampleRate;
      const minutes = Math.floor(exactDuration / 60);
      const seconds = (exactDuration % 60);
      const frames = (exactDuration * 30) % 30; // Assuming 30fps for frame calculation
      
      info.innerHTML = `
        <h3>${track.filename}</h3>
        <p><strong>Duration:</strong> ${exactDuration.toFixed(6)}s (${minutes}:${seconds.toFixed(2)}) | <strong>Samples:</strong> ${totalSamples.toLocaleString()}</p>
        <p><strong>Audio Info:</strong> ${track.channels} ch | ${track.sampleRate} Hz | <strong>Timecode:</strong> ${Math.floor(seconds)}:${((seconds % 1) * 100).toFixed(0).padStart(2, '0')}</p>
      `;
      
      // Interactive waveform canvas
      const waveformContainer = document.createElement('div');
      waveformContainer.className = 'waveform-container';
      
      const canvas = document.createElement('canvas');
      canvas.width = 700;
      canvas.height = 120;
      canvas.className = 'waveform';
      waveformContainer.appendChild(canvas);
      
      // Loop controls
      const controls = document.createElement('div');
      controls.className = 'loop-controls';
      
      const playBtn = document.createElement('button');
      playBtn.textContent = 'Play Loop';
      
      const stopBtn = document.createElement('button');
      stopBtn.textContent = 'Stop';
      
      const testBtn = document.createElement('button');
      testBtn.textContent = 'Test Audio';
      testBtn.style.background = '#cc0000';
      testBtn.title = 'Simple test to play raw audio';
      
      const findLoopBtn = document.createElement('button');
      findLoopBtn.textContent = 'Find Loop Point';
      findLoopBtn.style.background = '#006600';
      findLoopBtn.title = 'Reset to algorithm-detected optimal loop points';
      
      const nextLoopBtn = document.createElement('button');
      nextLoopBtn.textContent = 'Next Window →';
      nextLoopBtn.style.background = '#0066cc';
      nextLoopBtn.style.fontSize = '12px';
      nextLoopBtn.title = 'Move to next sequential audio window starting where current loop ends';
      
      let currentLoopIndex = 0;
      
      const adjustContainer = document.createElement('div');
      adjustContainer.style.display = 'flex';
      adjustContainer.style.gap = '5px';
      adjustContainer.style.alignItems = 'center';
      
      const halveBtn = document.createElement('button');
      halveBtn.textContent = '÷2 Bars';
      halveBtn.style.background = '#cc6600';
      halveBtn.style.fontSize = '12px';
      halveBtn.title = 'Halve the loop length (fewer bars)';
      
      const doubleBtn = document.createElement('button');
      doubleBtn.textContent = '×2 Bars';
      doubleBtn.style.background = '#cc6600';
      doubleBtn.style.fontSize = '12px';
      doubleBtn.title = 'Double the loop length (more bars)';
      
      const fullTrackBtn = document.createElement('button');
      fullTrackBtn.textContent = 'Full Track';
      fullTrackBtn.style.background = '#660066';
      fullTrackBtn.style.fontSize = '12px';
      fullTrackBtn.title = 'Use entire track as loop';
      
      const saveLoopBtn = document.createElement('button');
      saveLoopBtn.textContent = 'Save Loop';
      saveLoopBtn.style.background = '#009900';
      saveLoopBtn.style.fontSize = '12px';
      saveLoopBtn.title = 'Save this loop with title, description, and tag';
      
      // Time adjustment controls for long loops
      const timeAdjustContainer = document.createElement('div');
      timeAdjustContainer.style.display = 'flex';
      timeAdjustContainer.style.gap = '5px';
      timeAdjustContainer.style.alignItems = 'center';
      timeAdjustContainer.style.marginTop = '5px';
      
      const compressBtn = document.createElement('button');
      compressBtn.textContent = 'Compress to 12s';
      compressBtn.style.background = '#cc3300';
      compressBtn.style.fontSize = '11px';
      compressBtn.title = 'Time-stretch to fit 12-second limit';
      
      const stretchMethodSelect = document.createElement('select');
      stretchMethodSelect.style.fontSize = '11px';
      stretchMethodSelect.innerHTML = `
        <option value="pitch">Pitch-based (faster tempo)</option>
        <option value="tempo">Tempo-based (preserve pitch)</option>
      `;
      
      timeAdjustContainer.appendChild(compressBtn);
      timeAdjustContainer.appendChild(stretchMethodSelect);
      
      adjustContainer.appendChild(halveBtn);
      adjustContainer.appendChild(doubleBtn);
      adjustContainer.appendChild(fullTrackBtn);
      adjustContainer.appendChild(saveLoopBtn);
      
      // Only show time adjust for loops over 12 seconds
      const timeAdjustWrapper = document.createElement('div');
      timeAdjustWrapper.appendChild(timeAdjustContainer);
      
      const timeDisplay = document.createElement('div');
      timeDisplay.className = 'time-display';
      
      // Volume slider
      const volumeContainer = document.createElement('div');
      volumeContainer.className = 'slider-container';
      volumeContainer.innerHTML = `
        <label>Volume:</label>
        <input type="range" class="slider" min="0" max="1" step="0.1" value="0.5">
      `;
      
      controls.appendChild(playBtn);
      controls.appendChild(stopBtn);
      controls.appendChild(testBtn);
      controls.appendChild(findLoopBtn);
      controls.appendChild(nextLoopBtn);
      controls.appendChild(adjustContainer);
      
      // Show time adjustment only for loops over 12 seconds
      const loopDuration = track.analysis.loopEnd - track.analysis.loopStart;
      if (loopDuration > 12) {
        controls.appendChild(timeAdjustWrapper);
      }
      
      controls.appendChild(timeDisplay);
      controls.appendChild(volumeContainer);
      
      // Validation check for expected benchmarks
      function getValidationStatus(track) {
        const duration = track.duration;
        const bpm = track.analysis.bpm;
        const loopDuration = track.analysis.loopEnd - track.analysis.loopStart;
        
        let validation = '';
        
        // Check for specific test cases
        if (track.filename.includes('Bassline For Doppler Song - 11')) {
          // Short loop test: Should be ~2.15 seconds and detect ~91.73 BPM
          const expectedDuration = 2.15;
          const expectedBPM = 91.73;
          const durationMatch = Math.abs(duration - expectedDuration) < 0.5;
          const bpmMatch = Math.abs(bpm - expectedBPM) < 5;
          validation = `<strong>Validation:</strong> Duration ${durationMatch ? 'PASS' : 'FAIL'} (${duration.toFixed(2)}s vs ~${expectedDuration}s), BPM ${bpmMatch ? 'PASS' : 'FAIL'} (${bpm.toFixed(1)} vs ~${expectedBPM})<br>`;
        } else if (track.filename.includes('longer')) {
          // Long track test: Should find a segment around 2.15 seconds at ~91.73 BPM
          const expectedSegment = 2.15;
          const expectedBPM = 91.73;
          const segmentMatch = Math.abs(loopDuration - expectedSegment) < 0.5;
          const bpmMatch = Math.abs(bpm - expectedBPM) < 5;
          validation = `<strong>Validation:</strong> Found segment ${segmentMatch ? 'PASS' : 'FAIL'} (${loopDuration.toFixed(2)}s vs ~${expectedSegment}s), BPM ${bpmMatch ? 'PASS' : 'FAIL'} (${bpm.toFixed(1)} vs ~${expectedBPM})<br>`;
        } else if (track.filename.includes('Jazz') || track.filename.includes('Drumset')) {
          // Jazz drums test: Should be 152 BPM and ~183.75 seconds (3:03.75)
          const expectedDuration = 183.75; // 3:03.75 in seconds
          const expectedBPM = 152;
          const durationMatch = Math.abs(duration - expectedDuration) < 2;
          const bpmMatch = Math.abs(bpm - expectedBPM) < 3;
          validation = `<strong>Validation:</strong> Duration ${durationMatch ? 'PASS' : 'FAIL'} (${Math.floor(duration/60)}:${(duration%60).toFixed(2)} vs 3:03.75), BPM ${bpmMatch ? 'PASS' : 'FAIL'} (${bpm.toFixed(1)} vs 152)<br>`;
        } else if (track.filename.includes('Drive Through')) {
          // Drive Through test: Should be ~14s and need compression to 12s
          const expectedDuration = 14;
          const durationMatch = Math.abs(duration - expectedDuration) < 1;
          const needsCompression = loopDuration > 12;
          validation = `<strong>Validation:</strong> Duration ${durationMatch ? 'PASS' : 'FAIL'} (${duration.toFixed(2)}s vs ~${expectedDuration}s), Compression ${needsCompression ? 'REQUIRED' : 'NOT NEEDED'} (Loop: ${loopDuration.toFixed(2)}s > 12s limit)<br>`;
        }
        
        return validation;
      }
      
      // Analysis display
      const librosaData = document.createElement('div');
      librosaData.className = 'librosa-analysis';
      librosaData.innerHTML = `
        ${getValidationStatus(track)}
        <strong>Musical Analysis:</strong><br>
        RMS: ${track.analysis.rms.toFixed(6)}<br>
        Peak: ${track.analysis.peak.toFixed(6)}<br>
        Spectral Centroid: ${track.analysis.spectralCentroid.toFixed(2)} Hz<br>
        Zero Crossing Rate: ${track.analysis.zeroCrossingRate.toFixed(6)}<br>
        <strong>Musical Timing:</strong><br>
        BPM: ${track.analysis.bpm ? track.analysis.bpm.toFixed(2) : 'N/A'}<br>
        Bar Duration: ${track.analysis.barDuration ? track.analysis.barDuration.toFixed(3) + 's' : 'N/A'}<br>
        Musical Division: ${track.analysis.musicalDivision ? track.analysis.musicalDivision.toFixed(2) + ' bars' : 'N/A'}<br>
        Loop Confidence: ${track.analysis.confidence.toFixed(6)}
      `;
      
      const loopData = document.createElement('div');
      loopData.className = 'analysis-data';
      
      function updateLoopData(start, end) {
        const bpm = track.analysis.bpm || 120;
        const barDuration = (60 / bpm) * 4; // 4/4 time signature
        const loopDuration = end - start;
        const bars = loopDuration / barDuration;
        
        // Update validation with current loop duration
        const needsCompression = loopDuration > 12;
        let validationUpdate = '';
        
        if (track.filename.includes('Drive Through')) {
          const expectedDuration = 14;
          const durationMatch = Math.abs(track.duration - expectedDuration) < 1;
          validationUpdate = `<strong>Validation:</strong> Duration ${durationMatch ? 'PASS' : 'FAIL'} (${track.duration.toFixed(2)}s vs ~${expectedDuration}s), Compression ${needsCompression ? 'REQUIRED' : 'NOT NEEDED'} (Loop: ${loopDuration.toFixed(2)}s ${needsCompression ? '>' : '≤'} 12s limit)<br>`;
          
          // Update the validation display in the librosa analysis section
          const currentHTML = librosaData.innerHTML;
          const newHTML = currentHTML.replace(/<strong>Validation:<\/strong>.*?<br>/s, validationUpdate);
          librosaData.innerHTML = newHTML;
        }
        
        loopData.innerHTML = `
          <strong>Loop Points:</strong><br>
          Start: ${start.toFixed(4)}s<br>
          End: ${end.toFixed(4)}s<br>
          Duration: ${loopDuration.toFixed(4)}s<br>
          <strong>Musical Length:</strong> ${bars.toFixed(2)} bars<br>
          <em>Click or drag on waveform to adjust</em>
        `;
        
        // Show/hide compression controls based on current loop duration
        if (needsCompression) {
          if (!timeAdjustWrapper.parentNode) {
            controls.appendChild(timeAdjustWrapper);
          }
          timeAdjustWrapper.style.display = 'block';
        } else {
          timeAdjustWrapper.style.display = 'none';
        }
      }
      
      updateLoopData(track.analysis.loopStart, track.analysis.loopEnd);
      
      // Initialize components
      const editor = new WaveformEditor(canvas, track.buffer, track.analysis);
      const player = new LoopPlayer(track.buffer);
      player.setLoopPoints(track.analysis.loopStart, track.analysis.loopEnd);
      
      // Event handlers
      canvas.addEventListener('loopChange', (e) => {
        const { loopStart, loopEnd } = e.detail;
        player.setLoopPoints(loopStart, loopEnd);
        updateLoopData(loopStart, loopEnd);
        timeDisplay.textContent = `Loop: ${loopStart.toFixed(3)}s - ${loopEnd.toFixed(3)}s`;
      });
      
      playBtn.addEventListener('click', async () => {
        try {
          await player.play();
          playBtn.classList.add('active');
          stopBtn.classList.remove('active');
        } catch (error) {
          console.error('Failed to play audio:', error);
          alert('Failed to play audio. Please try again.');
        }
      });
      
      stopBtn.addEventListener('click', () => {
        player.stop();
        stopBtn.classList.add('active');
        playBtn.classList.remove('active');
      });
      
      testBtn.addEventListener('click', async () => {
        console.log('Testing simple audio playback...');
        
        try {
          const audioContext = new (window.AudioContext || window.webkitAudioContext)();
          
          if (audioContext.state === 'suspended') {
            await audioContext.resume();
            console.log('Test: Audio context resumed');
          }
          
          const source = audioContext.createBufferSource();
          const gain = audioContext.createGain();
          
          source.buffer = track.buffer;
          source.connect(gain);
          gain.connect(audioContext.destination);
          gain.gain.value = 0.8;
          
          console.log('Test: Starting audio from beginning for 3 seconds...');
          source.start(0, 0, 3); // Play first 3 seconds
          
          setTimeout(() => {
            source.stop();
            console.log('Test: Audio stopped');
          }, 3000);
          
        } catch (error) {
          console.error('Test audio failed:', error);
        }
      });
      
      findLoopBtn.addEventListener('click', () => {
        console.log('Resetting to optimal loop points...');
        
        // Reset editor to original algorithm-detected points
        editor.loopStart = track.analysis.loopStart;
        editor.loopEnd = track.analysis.loopEnd;
        editor.draw();
        
        // Update player
        player.setLoopPoints(track.analysis.loopStart, track.analysis.loopEnd);
        
        // Update displays
        updateLoopData(track.analysis.loopStart, track.analysis.loopEnd);
        timeDisplay.textContent = `Loop: ${track.analysis.loopStart.toFixed(3)}s - ${track.analysis.loopEnd.toFixed(3)}s`;
        
        // Reset the loop navigation
        currentLoopIndex = 0;
        const estimatedWindows = Math.floor(track.duration / (track.analysis.loopEnd - track.analysis.loopStart));
        nextLoopBtn.textContent = `Next Window → (1/${estimatedWindows})`;
        
        console.log(`Reset to optimal: ${track.analysis.loopStart.toFixed(3)}s - ${track.analysis.loopEnd.toFixed(3)}s`);
      });
      
      nextLoopBtn.addEventListener('click', () => {
        const bpm = track.analysis.bpm || 120;
        const barDuration = (60 / bpm) * 4; // 4/4 time signature
        const currentLoopEnd = editor.loopEnd;
        const remainingTime = track.duration - currentLoopEnd;
        
        // Calculate next sequential loop duration based on current loop length
        const currentLoopDuration = editor.loopEnd - editor.loopStart;
        let nextLoopDuration = currentLoopDuration; // Default to same length
        
        // If we don't have enough remaining time for the same length, try smaller divisions
        if (remainingTime < nextLoopDuration) {
          const musicalDivisions = [0.5, 1, 2, 4].map(div => div * barDuration);
          nextLoopDuration = musicalDivisions.find(duration => duration <= remainingTime) || remainingTime;
        }
        
        // Don't exceed 12 second limit for loops
        nextLoopDuration = Math.min(nextLoopDuration, 12.0);
        
        // Calculate new loop points starting from current loop end
        const nextStart = currentLoopEnd;
        const nextEnd = Math.min(nextStart + nextLoopDuration, track.duration);
        
        if (nextEnd - nextStart < 0.5) {
          console.log('Not enough remaining audio for next loop');
          // Wrap around to beginning
          editor.loopStart = 0;
          editor.loopEnd = Math.min(nextLoopDuration, track.duration);
          currentLoopIndex = 0;
        } else {
          // Move to next sequential segment
          editor.loopStart = nextStart;
          editor.loopEnd = nextEnd;
          currentLoopIndex++;
        }
        
        const bars = (editor.loopEnd - editor.loopStart) / barDuration;
        
        console.log(`Next sequential loop: ${editor.loopStart.toFixed(3)}s - ${editor.loopEnd.toFixed(3)}s`);
        console.log(`  Duration: ${(editor.loopEnd - editor.loopStart).toFixed(3)}s (${bars.toFixed(1)} bars)`);
        console.log(`  Remaining audio: ${(track.duration - editor.loopEnd).toFixed(3)}s`);
        
        // Update editor and player
        editor.draw();
        player.setLoopPoints(editor.loopStart, editor.loopEnd);
        
        // Update displays
        updateLoopData(editor.loopStart, editor.loopEnd);
        timeDisplay.textContent = `Loop: ${editor.loopStart.toFixed(3)}s - ${editor.loopEnd.toFixed(3)}s (${bars.toFixed(1)} bars)`;
        
        // Update button text
        const maxWindows = Math.floor(track.duration / (editor.loopEnd - editor.loopStart));
        nextLoopBtn.textContent = `Next Window → (${currentLoopIndex + 1}/${maxWindows})`;
      });
      
      volumeContainer.querySelector('.slider').addEventListener('input', (e) => {
        player.setVolume(parseFloat(e.target.value));
      });
      
      // Musical bar-based loop adjustment controls
      halveBtn.addEventListener('click', () => {
        const bpm = track.analysis.bpm || 120;
        const barDuration = (60 / bpm) * 4; // 4/4 time signature
        const currentBars = Math.round((editor.loopEnd - editor.loopStart) / barDuration);
        const newBars = Math.max(0.5, currentBars / 2); // Allow half-bar minimum
        const newDuration = newBars * barDuration;
        
        // Keep loop start, adjust end
        editor.loopEnd = Math.min(track.duration, editor.loopStart + newDuration);
        editor.draw();
        player.setLoopPoints(editor.loopStart, editor.loopEnd);
        updateLoopData(editor.loopStart, editor.loopEnd);
        timeDisplay.textContent = `Loop: ${editor.loopStart.toFixed(3)}s - ${editor.loopEnd.toFixed(3)}s`;
        console.log(`Reduced to ${newBars} bars (${newDuration.toFixed(3)}s) at ${bpm.toFixed(1)} BPM`);
      });
      
      doubleBtn.addEventListener('click', () => {
        const bpm = track.analysis.bpm || 120;
        const barDuration = (60 / bpm) * 4; // 4/4 time signature
        const currentBars = Math.round((editor.loopEnd - editor.loopStart) / barDuration);
        const newBars = currentBars * 2;
        const newDuration = newBars * barDuration;
        
        // Keep loop start, adjust end (but don't exceed track duration)
        editor.loopEnd = Math.min(track.duration, editor.loopStart + newDuration);
        editor.draw();
        player.setLoopPoints(editor.loopStart, editor.loopEnd);
        updateLoopData(editor.loopStart, editor.loopEnd);
        timeDisplay.textContent = `Loop: ${editor.loopStart.toFixed(3)}s - ${editor.loopEnd.toFixed(3)}s`;
        console.log(`Extended to ${newBars} bars (${newDuration.toFixed(3)}s) at ${bpm.toFixed(1)} BPM`);
      });
      
      fullTrackBtn.addEventListener('click', () => {
        editor.loopStart = 0;
        editor.loopEnd = track.duration;
        editor.draw();
        player.setLoopPoints(editor.loopStart, editor.loopEnd);
        updateLoopData(editor.loopStart, editor.loopEnd);
        timeDisplay.textContent = `Loop: ${editor.loopStart.toFixed(3)}s - ${editor.loopEnd.toFixed(3)}s`;
        console.log(`Set to full track ${track.duration.toFixed(3)}s`);
      });
      
      // Save loop functionality
      saveLoopBtn.addEventListener('click', () => {
        showSaveLoopModal(track, editor.loopStart, editor.loopEnd);
      });
      
      // Time compression for long loops - always attach event listener
      compressBtn.addEventListener('click', async () => {
        const currentLoopDuration = editor.loopEnd - editor.loopStart;
        const method = stretchMethodSelect.value;
        const targetDuration = 12.0;
        const compressionRatio = targetDuration / currentLoopDuration;
          
        console.log(`Compressing ${currentLoopDuration.toFixed(2)}s to ${targetDuration}s (ratio: ${compressionRatio.toFixed(3)}) using ${method} method`);
          
        
        if (currentLoopDuration <= 12.0) {
          alert('Loop is already 12 seconds or less. No compression needed.');
          return;
        }
        
        try {
          let compressedBuffer;
          
          if (method === 'pitch') {
            // Simple pitch-based compression (changes pitch and tempo)
            compressedBuffer = await pitchBasedCompress(track.buffer, compressionRatio);
          } else {
            // Tempo-based compression (preserves pitch, complex algorithm)
            compressedBuffer = await tempoBasedCompress(track.buffer, compressionRatio);
          }
          
          // Update the track with compressed audio
          track.buffer = compressedBuffer;
          track.duration = compressedBuffer.duration;
          track.sampleRate = compressedBuffer.sampleRate;
          track.channels = compressedBuffer.numberOfChannels;
          
          console.log('Re-analyzing compressed audio with Librosa...');
          
          // Re-run full Librosa analysis on compressed audio
          const newAnalysis = await librosaLoopAnalysis(compressedBuffer);
          track.analysis = newAnalysis;
          
          // Use the new analysis results for optimal loop points
          editor.loopStart = newAnalysis.loopStart;
          editor.loopEnd = newAnalysis.loopEnd;
          editor.audioBuffer = compressedBuffer;
          
          // Update player with new optimal loop points
          player.audioBuffer = compressedBuffer;
          player.setLoopPoints(newAnalysis.loopStart, newAnalysis.loopEnd);
          
          // Update all displays with new analysis
          editor.draw();
          updateLoopData(newAnalysis.loopStart, newAnalysis.loopEnd);
          timeDisplay.textContent = `Loop: ${newAnalysis.loopStart.toFixed(3)}s - ${newAnalysis.loopEnd.toFixed(3)}s (COMPRESSED & RE-ANALYZED)`;
          
          // Update the analysis display with new data
          const newBars = (newAnalysis.loopEnd - newAnalysis.loopStart) / ((60 / newAnalysis.bpm) * 4);
          librosaData.innerHTML = `
            <strong>Musical Analysis (COMPRESSED):</strong><br>
            RMS: ${newAnalysis.rms.toFixed(6)}<br>
            Peak: ${newAnalysis.peak.toFixed(6)}<br>
            Spectral Centroid: ${newAnalysis.spectralCentroid.toFixed(2)} Hz<br>
            Zero Crossing Rate: ${newAnalysis.zeroCrossingRate.toFixed(6)}<br>
            <strong>Musical Timing (NEW):</strong><br>
            BPM: ${newAnalysis.bpm ? newAnalysis.bpm.toFixed(2) : 'N/A'}<br>
            Bar Duration: ${newAnalysis.barDuration ? newAnalysis.barDuration.toFixed(3) + 's' : 'N/A'}<br>
            Musical Division: ${newAnalysis.musicalDivision ? newAnalysis.musicalDivision.toFixed(2) + ' bars' : 'N/A'}<br>
            Loop Confidence: ${newAnalysis.confidence.toFixed(6)}
          `;
          
          // Reset loop navigation with new candidates
          currentLoopIndex = 0;
          if (newAnalysis.allCandidates && newAnalysis.allCandidates.length > 1) {
            nextLoopBtn.textContent = `Next Window → (1/${newAnalysis.allCandidates.length})`;
            nextLoopBtn.style.display = 'inline-block';
          } else {
            const estimatedWindows = Math.floor(compressedBuffer.duration / (newAnalysis.loopEnd - newAnalysis.loopStart));
            nextLoopBtn.textContent = `Next Window → (1/${estimatedWindows})`;
          }
          
          // Hide time adjust controls since it's now under 12s
          timeAdjustWrapper.style.display = 'none';
          
          // Update the track info display at the top
          const totalSamples = compressedBuffer.length;
          const exactDuration = totalSamples / compressedBuffer.sampleRate;
          const minutes = Math.floor(exactDuration / 60);
          const seconds = (exactDuration % 60);
          
          info.innerHTML = `
            <h3>${track.filename} (COMPRESSED)</h3>
            <p><strong>Duration:</strong> ${exactDuration.toFixed(6)}s (${minutes}:${seconds.toFixed(2)}) | <strong>Samples:</strong> ${totalSamples.toLocaleString()}</p>
            <p><strong>Audio Info:</strong> ${track.channels} ch | ${track.sampleRate} Hz | <strong>Timecode:</strong> ${Math.floor(seconds)}:${((seconds % 1) * 100).toFixed(0).padStart(2, '0')}</p>
          `;
          
          console.log(`Compression & re-analysis complete!`);
          console.log(`New optimal loop: ${newAnalysis.loopStart.toFixed(3)}s - ${newAnalysis.loopEnd.toFixed(3)}s`);
          console.log(`New BPM: ${newAnalysis.bpm.toFixed(1)}, Bars: ${newBars.toFixed(1)}`);
          
        } catch (error) {
          console.error('Compression failed:', error);
          alert('Time compression failed. This feature requires more complex audio processing.');
        }
      });
      
      // Initial state
      timeDisplay.textContent = `Loop: ${track.analysis.loopStart.toFixed(3)}s - ${track.analysis.loopEnd.toFixed(3)}s`;
      
      // Initialize the next window button with estimated window count
      const estimatedWindows = Math.floor(track.duration / (track.analysis.loopEnd - track.analysis.loopStart));
      if (estimatedWindows > 1) {
        nextLoopBtn.textContent = `Next Window → (1/${estimatedWindows})`;
        nextLoopBtn.style.display = 'inline-block';
      } else {
        nextLoopBtn.style.display = 'none';
      }
      
      container.appendChild(info);
      container.appendChild(waveformContainer);
      container.appendChild(controls);
      container.appendChild(librosaData);
      container.appendChild(loopData);
      
      return container;
    }

    // Handle file upload
    document.getElementById('uploadForm').addEventListener('submit', async (e) => {
      e.preventDefault();
      
      const fileInput = document.getElementById('fileInput');
      const file = fileInput.files[0];
      
      if (!file) return;
      
      try {
        console.log('Starting Librosa analysis...');
        
        const container = document.getElementById('tracks');
        const loading = document.createElement('div');
        loading.textContent = 'Analyzing with Librosa algorithms...';
        loading.className = 'loading';
        container.appendChild(loading);
        
        const track = await processAudioFile(file);
        const trackElement = createAdvancedTrackElement(track);
        
        loading.remove();
        container.appendChild(trackElement);
        
        fileInput.value = '';
        
        console.log('Librosa Loop Editor ready!');
        
      } catch (error) {
        console.error('Failed:', error);
        alert('Failed to process: ' + error.message);
        
        const loading = document.querySelector('.loading');
        if (loading) loading.remove();
      }
    });

    // Test track handlers
    document.getElementById('testShortLoop').addEventListener('click', async () => {
      console.log('Testing short loop with musical timing analysis...');
      await loadTestTrack('audio/Bassline For Doppler Song - 11.aif', 'Short Loop Sample', false);
    });

    document.getElementById('testLongTrack').addEventListener('click', async () => {
      console.log('Testing long track with musical timing analysis...');
      await loadTestTrack('audio/Bassline For Doppler Song longer.aif', 'Long Track with Musical Loop Detection', false);
    });

    document.getElementById('testJazzyDrums').addEventListener('click', async () => {
      console.log('Testing jazz drums - Expected: 152 BPM, 3:03.75 duration...');
      await loadTestTrack('audio/12-8-Jazzy-Drumset-03.aif', 'Jazz Drums Test (152 BPM Validation)', false);
    });

    document.getElementById('testDriveThrough').addEventListener('click', async () => {
      console.log('Testing Drive Through Beat - Expected: 14s full loop, needs compression...');
      await loadTestTrack('audio/Drive Through Beat.aif', 'Drive Through Beat (14s → Time Adjust Test)', false);
    });

    // Load reference track and create template
    async function loadReferenceTrack() {
      try {
        const container = document.getElementById('tracks');
        const loading = document.createElement('div');
        loading.textContent = 'Loading reference loop and creating template...';
        loading.className = 'loading';
        container.appendChild(loading);

        // Load the perfect loop
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const audioBuffer = await loadAudioBuffer('audio/Bassline For Doppler Song - 11.aif', audioContext);
        
        // Analyze it first
        const analysis = await librosaLoopAnalysis(audioBuffer, false);
        
        // Create reference template from this perfect loop
        referenceLoopTemplate = await createReferenceTemplate(audioBuffer, analysis.loopStart, analysis.loopEnd);
        
        const track = {
          url: 'audio/Bassline For Doppler Song - 11.aif',
          filename: 'Perfect 2.6s Loop (Reference Template Created)',
          duration: audioBuffer.duration,
          sampleRate: audioBuffer.sampleRate,
          channels: audioBuffer.numberOfChannels,
          buffer: audioBuffer,
          analysis: analysis
        };

        const trackElement = createAdvancedTrackElement(track);
        
        loading.remove();
        container.appendChild(trackElement);
        
        // Update button to show template is ready
        document.getElementById('testLongTrack').style.background = '#ff6600';
        document.getElementById('testLongTrack').textContent = 'Test: 46s Track (Reference Ready!)';
        
        console.log('Reference template created and ready for guided analysis!');
        
      } catch (error) {
        console.error('Reference track failed:', error);
        alert('Failed to create reference template: ' + error.message);
        
        const loading = document.querySelector('.loading');
        if (loading) loading.remove();
      }
    }

    async function loadTestTrack(url, description, useReference = false) {
      try {
        const container = document.getElementById('tracks');
        const loading = document.createElement('div');
        loading.textContent = `Loading ${description}...`;
        loading.className = 'loading';
        container.appendChild(loading);

        // Load and process the test track
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const audioBuffer = await loadAudioBuffer(url, audioContext);
        
        // Use reference-guided analysis if requested
        const analysis = await librosaLoopAnalysis(audioBuffer, useReference);
        
        const track = {
          url: url,
          filename: description,
          duration: audioBuffer.duration,
          sampleRate: audioBuffer.sampleRate,
          channels: audioBuffer.numberOfChannels,
          buffer: audioBuffer,
          analysis: analysis
        };

        const trackElement = createAdvancedTrackElement(track);
        
        loading.remove();
        container.appendChild(trackElement);
        
        if (useReference) {
          console.log(`${description} analyzed using reference template!`);
        } else {
          console.log(`${description} loaded and analyzed!`);
        }
        
      } catch (error) {
        console.error('Test track failed:', error);
        alert('Failed to load test track: ' + error.message);
        
        const loading = document.querySelector('.loading');
        if (loading) loading.remove();
      }
    }

    // Save loop modal functionality
    function showSaveLoopModal(track, loopStart, loopEnd) {
      // Create modal overlay
      const modal = document.createElement('div');
      modal.style.cssText = `
        position: fixed; top: 0; left: 0; width: 100%; height: 100%;
        background: rgba(0,0,0,0.8); z-index: 1000; display: flex;
        align-items: center; justify-content: center;
      `;
      
      // Create modal content
      const modalContent = document.createElement('div');
      modalContent.style.cssText = `
        background: #222; padding: 30px; border-radius: 10px; width: 400px;
        color: #fff; font-family: monospace;
      `;
      
      const loopDuration = loopEnd - loopStart;
      const bpm = track.analysis.bpm || 120;
      const barDuration = (60 / bpm) * 4;
      const bars = loopDuration / barDuration;
      
      modalContent.innerHTML = `
        <h3 style="margin-top: 0; color: #00ff00;">Save Loop - BeaatsLoops</h3>
        <div style="background: #111; padding: 10px; border-radius: 5px; margin: 10px 0;">
          <strong>Loop Info:</strong><br>
          Duration: ${loopDuration.toFixed(3)}s (${bars.toFixed(1)} bars)<br>
          BPM: ${bpm.toFixed(1)}<br>
          Range: ${loopStart.toFixed(3)}s - ${loopEnd.toFixed(3)}s
        </div>
        
        <div style="margin: 15px 0;">
          <label style="display: block; margin-bottom: 5px; color: #ccc;">Loop Title:</label>
          <input type="text" id="loopTitle" style="width: 100%; padding: 8px; background: #333; color: #fff; border: 1px solid #555; border-radius: 4px;" placeholder="e.g., Beat Boy">
        </div>
        
        <div style="margin: 15px 0;">
          <label style="display: block; margin-bottom: 5px; color: #ccc;">Description:</label>
          <textarea id="loopDescription" style="width: 100%; height: 60px; padding: 8px; background: #333; color: #fff; border: 1px solid #555; border-radius: 4px; resize: vertical;" placeholder="Brief description of the loop..."></textarea>
        </div>
        
        <div style="margin: 15px 0;">
          <label style="display: block; margin-bottom: 5px; color: #ccc;">Tag (no # needed):</label>
          <input type="text" id="loopTag" style="width: 100%; padding: 8px; background: #333; color: #fff; border: 1px solid #555; border-radius: 4px;" placeholder="e.g., beatboy">
          <small style="color: #888;">Will create link: #yourtag@username</small>
        </div>
        
        <div style="margin: 15px 0;">
          <label style="display: block; margin-bottom: 5px; color: #ccc;">Username:</label>
          <input type="text" id="loopUsername" style="width: 100%; padding: 8px; background: #333; color: #fff; border: 1px solid #555; border-radius: 4px;" placeholder="e.g., rebel123">
        </div>
        
        <div style="margin-top: 20px; display: flex; gap: 10px; justify-content: flex-end;">
          <button id="cancelSave" style="padding: 10px 20px; background: #666; color: #fff; border: none; border-radius: 4px; cursor: pointer;">Cancel</button>
          <button id="confirmSave" style="padding: 10px 20px; background: #009900; color: #fff; border: none; border-radius: 4px; cursor: pointer;">Save Loop</button>
        </div>
      `;
      
      modal.appendChild(modalContent);
      document.body.appendChild(modal);
      
      // Focus on title input
      setTimeout(() => document.getElementById('loopTitle').focus(), 100);
      
      // Event handlers
      document.getElementById('cancelSave').addEventListener('click', () => {
        document.body.removeChild(modal);
      });
      
      document.getElementById('confirmSave').addEventListener('click', () => {
        const title = document.getElementById('loopTitle').value.trim();
        const description = document.getElementById('loopDescription').value.trim();
        const tag = document.getElementById('loopTag').value.trim().toLowerCase().replace(/[^a-z0-9]/g, '');
        const username = document.getElementById('loopUsername').value.trim().toLowerCase().replace(/[^a-z0-9]/g, '');
        
        if (!title || !tag || !username) {
          alert('Please fill in Title, Tag, and Username fields');
          return;
        }
        
        // Check if loop exceeds 12-second limit
        if (loopDuration > 12.0) {
          alert(`Loop duration is ${loopDuration.toFixed(2)}s, which exceeds the 12-second limit. Please use the "Compress to 12s" feature first, or adjust the loop length.`);
          return;
        }
        
        const loopData = {
          title: title,
          description: description,
          tag: tag,
          username: username,
          link: `#${tag}@${username}`,
          audio: {
            filename: track.filename,
            duration: track.duration,
            sampleRate: track.sampleRate,
            channels: track.channels
          },
          loop: {
            start: loopStart,
            end: loopEnd,
            duration: loopDuration,
            bars: bars,
            bpm: bpm
          },
          timestamp: new Date().toISOString()
        };
        
        console.log('Saved Loop Data:', loopData);
        
        // Here you would typically send to a server
        // For now, just show success and copy link
        const link = loopData.link;
        navigator.clipboard.writeText(link).then(() => {
          alert(`Loop saved! Link copied to clipboard: ${link}`);
        }).catch(() => {
          alert(`Loop saved! Your link: ${link}`);
        });
        
        document.body.removeChild(modal);
      });
      
      // Close on outside click
      modal.addEventListener('click', (e) => {
        if (e.target === modal) {
          document.body.removeChild(modal);
        }
      });
    }

    console.log('Librosa Loop Editor Ready - 2023 Research Integration');
  </script>
</body>
</html>