function detectBPM(t,e){const o=2048,n=512,i=Math.floor((t.length-o)/n),a=[];for(let e=1;e<i;e++){const i=e*n,s=t.slice(i,i+o),r=Math.sqrt(s.reduce(((t,e)=>t+e*e),0)/o),c=t.slice((e-1)*n,i),l=Math.sqrt(c.reduce(((t,e)=>t+e*e),0)/o);a.push(Math.max(0,r-l))}const s=Math.floor(60/180*e/n),r=Math.floor(1*e/n),c=[];for(let t=s;t<=r&&t<a.length/2;t++){let o=0,i=0;for(let e=0;e<a.length-t;e++)o+=a[e]*a[e+t],i++;o/=i;const s=60*e/(t*n);c.push({bpm:s,correlation:o,period:t})}c.sort(((t,e)=>e.correlation-t.correlation));let l=c[0].bpm,u=c[0].correlation;if(l<90){const t=2*l;if(t<=180){const e=Math.floor(c[0].period/2);if(e>=s){let o=0,n=0;for(let t=0;t<a.length-e;t++)o+=a[t]*a[t+e],n++;o/=n,o>.7*u&&(l=t,u=o)}}}if(l>160){const t=l/2;if(t>=60){const e=2*c[0].period;if(e<=r&&e<a.length/2){let o=0,n=0;for(let t=0;t<a.length-e;t++)o+=a[t]*a[t+e],n++;o/=n,o>.8*u&&(l=t,u=o)}}}return{bpm:l,confidence:u}}async function loadAudioBuffer(t,e=new AudioContext){const o=await fetch(t),n=await o.arrayBuffer();return await e.decodeAudioData(n)}function computeRMS(t){const e=t.getChannelData(0);let o=0;for(let t=0;t<e.length;t++){const n=e[t];o+=n*n}return Math.sqrt(o/e.length)}function computePeak(t){const e=t.getChannelData(0);let o=0;for(let t=0;t<e.length;t++){const n=Math.abs(e[t]);n>o&&(o=n)}return o}function computeZeroCrossingRate(t){const e=t.getChannelData(0);let o=0;for(let t=1;t<e.length;t++)e[t]>=0!=e[t-1]>=0&&o++;return o/e.length}var audioUtils=Object.freeze({__proto__:null,computePeak:computePeak,computeRMS:computeRMS,computeZeroCrossingRate:computeZeroCrossingRate,loadAudioBuffer:loadAudioBuffer});async function computeSpectrum(t,e=2048){const o=new OfflineAudioContext(1,t.length,t.sampleRate),n=o.createBufferSource();n.buffer=t;const i=o.createAnalyser();i.fftSize=e,n.connect(i),i.connect(o.destination),n.start(),await o.startRendering();const a=new Float32Array(i.frequencyBinCount);return i.getFloatFrequencyData(a),Array.from(a)}function computeSpectralCentroid(t){const e=t.getChannelData(0),o=2048;let n=0;for(let t=0;t<e.length-o;t+=o){const i=computeFFT(e.slice(t,t+o));let a=0,s=0;for(let t=0;t<i.length/2;t++){const e=Math.sqrt(i[2*t]**2+i[2*t+1]**2);a+=t*e,s+=e}s>0&&(n+=a/s)}return n/(e.length/o)*t.sampleRate/o}function computeFFT(t){const e=t.length,o=new Float32Array(e),n=new Float32Array(e);for(let i=0;i<e;i++)o[i]=t[i],n[i]=0;for(let i=0;i<e;i++)for(let a=0;a<e;a++){const s=-2*Math.PI*i*a/e;o[i]+=t[a]*Math.cos(s),n[i]+=t[a]*Math.sin(s)}const i=new Float32Array(2*e);for(let t=0;t<e;t++)i[2*t]=o[t],i[2*t+1]=n[t];return i}var spectral=Object.freeze({__proto__:null,computeFFT:computeFFT,computeSpectralCentroid:computeSpectralCentroid,computeSpectrum:computeSpectrum});function calculateBeatAlignment(t,e){const o=t/(60/e),n=1-Math.abs(o-Math.round(o)),i=[1,2,4,8,16].reduce(((t,e)=>Math.abs(e-o)<Math.abs(t-o)?e:t));return.7*n+.3*Math.max(0,1-Math.abs(i-o)/2)}let DEBUG_ENABLED=Boolean("undefined"!=typeof process&&process.env&&process.env.PLECO_DEBUG||"undefined"!=typeof window&&window.PLECO_DEBUG);function setDebug(t){DEBUG_ENABLED=Boolean(t),"undefined"!=typeof window&&(window.PLECO_DEBUG=DEBUG_ENABLED),"undefined"!=typeof process&&process.env&&(process.env.PLECO_DEBUG=DEBUG_ENABLED?"true":"")}function debugLog(...t){DEBUG_ENABLED&&console.log(...t)}function findZeroCrossing(t,e){for(let o=e;o<t.length-1;o++)if(t[o]>=0&&t[o+1]<0)return o;return e}function findAudioStart(t,e,o=.01){const n=Math.floor(.1*e);for(let e=0;e<t.length-n;e+=n){const i=t.slice(e,e+n);if(Math.sqrt(i.reduce(((t,e)=>t+e*e),0)/n)>o){return findZeroCrossing(t,Math.max(0,e-n))}}return 0}function applyHannWindow(t){const e=new Float32Array(t.length);for(let o=0;o<t.length;o++){const n=.5*(1-Math.cos(2*Math.PI*o/(t.length-1)));e[o]=t[o]*n}return e}async function createReferenceTemplate(t,e,o){const n=t.getChannelData(0),i=t.sampleRate,a=Math.floor(e*i),s=Math.floor(o*i),r=n.slice(a,s),{computeRMS:c,computePeak:l,computeZeroCrossingRate:u}=await Promise.resolve().then((function(){return audioUtils})),{computeSpectralCentroid:h}=await Promise.resolve().then((function(){return spectral})),d={duration:o-e,samples:r.length,rms:c(t),peak:l(t),spectralCentroid:h(t),zeroCrossingRate:u(t),segment:r,sampleRate:i};return debugLog("Reference template created:",d),d}async function analyzeWithReference(t,e){const o=t.getChannelData(0),n=t.sampleRate,i=o.length,a=e.segment.length,s=Math.floor(.1*n);debugLog(`Reference analysis: scanning ${i} samples with template of ${a} samples`);let r={position:0,correlation:-1/0,confidence:0};for(let t=0;t<i-a;t+=s){const n=o.slice(t,t+a),i=Math.sqrt(n.reduce(((t,e)=>t+e*e),0)/n.length);if(i<.3*e.rms)continue;let s=0;for(let t=0;t<a;t++)s+=n[t]*e.segment[t];s/=a,s>r.correlation&&(r={position:t,correlation:s,confidence:s/Math.max(e.rms,i)})}const c={loopStart:findZeroCrossing(o,r.position)/n,loopEnd:findZeroCrossing(o,r.position+a)/n,confidence:r.confidence,referenceMatch:r.correlation,templateUsed:!0};return debugLog("Reference-guided result:",c),c}async function loopAnalysis(t,e=!1){debugLog("Starting Musical Timing-Aware Analysis...");const o=detectBPM(t.getChannelData(0),t.sampleRate),n=60/o.bpm*4;debugLog(`Detected BPM: ${o.bpm.toFixed(2)}, Bar duration: ${n.toFixed(3)}s`);const i=computeRMS(t),a=computePeak(t),s=await computeSpectrum(t),r=await musicalLoopAnalysis(t,o),c=computeSpectralCentroid(t),l=computeZeroCrossingRate(t);return{...r,rms:i,peak:a,spectrum:s,spectralCentroid:c,zeroCrossingRate:l,confidence:r.confidence*(1-Math.abs(i-.1)),bpm:o.bpm,barDuration:n,musicalInfo:{bpm:o.bpm,barDuration:n,beatDuration:60/o.bpm}}}async function musicalLoopAnalysis(t,e){const o=t.getChannelData(0),n=t.sampleRate,i=o.length,a=t.duration>15?findAudioStart(o,n):0;debugLog(`Musical Analysis: Audio starts at ${(a/n).toFixed(3)}s`);const s=60/e.bpm*4,r=60/e.bpm;debugLog(`Musical Analysis: Bar=${s.toFixed(3)}s, Beat=${r.toFixed(3)}s`);const c=[.5,1,2,4,8].map((t=>t*s)),l=[];for(const r of c){if(r>12||r>t.duration/2)continue;const c=Math.floor(r*n);if(a+2*c>i)continue;const u=applyHannWindow(o.slice(a,a+c)),h=applyHannWindow(o.slice(a+c,a+2*c));let d=0;for(let t=0;t<u.length;t++)d+=u[t]*h[t];d/=u.length;const p=findZeroCrossing(o,a),f=findZeroCrossing(o,a+c),g=calculateBeatAlignment(r,e.bpm),m=Math.abs(d)*g;l.push({loopStart:p/n,loopEnd:f/n,loopLength:r,correlation:d,confidence:m,musicalDivision:r/s,bpm:e.bpm,isMusicalBoundary:!0}),debugLog(`Testing ${(r/s).toFixed(1)} bars (${r.toFixed(3)}s): correlation=${d.toFixed(4)}, confidence=${m.toFixed(4)}`)}const u=l.reduce(((t,e)=>e.confidence>t.confidence?e:t),l[0]);if(u){const t=u.loopLength;for(let a=-.05;a<=.05;a+=.01){const r=t+a;if(r<=0)continue;const c=Math.floor(r*n);if(2*c>i)continue;const u=applyHannWindow(o.slice(0,c)),h=applyHannWindow(o.slice(c,2*c));let d=0;for(let t=0;t<u.length;t++)d+=u[t]*h[t];d/=u.length;const p=findZeroCrossing(o,0),f=findZeroCrossing(o,c);l.push({loopStart:p/n,loopEnd:f/n,loopLength:r,correlation:d,confidence:.9*Math.abs(d),musicalDivision:r/s,bpm:e.bpm,isMusicalBoundary:!1})}}if(t.duration>10&&u){const a=u.loopEnd,r=t.duration-a;for(const u of c){if(u>r||u>12)continue;const c=a,h=c+u;if(h>t.duration)continue;const d=Math.floor(c*n),p=Math.floor(h*n),f=p-d,g=applyHannWindow(o.slice(d,p)),m=applyHannWindow(o.slice(p,p+f));if(p+f>i)continue;let b=0;for(let t=0;t<g.length;t++)b+=g[t]*m[t];b/=g.length;const C=calculateBeatAlignment(u,e.bpm),M=Math.abs(b)*C*.8;l.push({loopStart:c,loopEnd:h,loopLength:u,correlation:b,confidence:M,musicalDivision:u/s,bpm:e.bpm,isMusicalBoundary:!0,isSequential:!0}),debugLog(`Sequential candidate: ${c.toFixed(3)}s - ${h.toFixed(3)}s (${(u/s).toFixed(1)} bars)`)}}l.sort(((t,e)=>e.confidence-t.confidence));let h;if(t.duration<15&&l.length>0){const o=l.find((e=>Math.abs(e.loopLength-t.duration)<.5));o?(h=o,debugLog(`Short track: Using full length ${h.loopLength.toFixed(3)}s as loop`)):(h={loopStart:0,loopEnd:t.duration,loopLength:t.duration,correlation:.8,confidence:.8,musicalDivision:t.duration/s,bpm:e.bpm,isMusicalBoundary:!1,isFullTrack:!0},debugLog(`Short track: Created full-track loop ${h.loopLength.toFixed(3)}s`))}else h=l[0]||{loopStart:0,loopEnd:Math.min(s,t.duration),loopLength:Math.min(s,t.duration),correlation:.5,confidence:.5,musicalDivision:1,bpm:e.bpm,isMusicalBoundary:!0};return debugLog(`Best musical loop: ${(h.musicalDivision||1).toFixed(2)} bars (${h.loopLength.toFixed(3)}s) at ${h.bpm.toFixed(1)} BPM`),{loopStart:h.loopStart,loopEnd:h.loopEnd,confidence:h.confidence,musicalDivision:h.musicalDivision||1,bpm:h.bpm,allCandidates:l.slice(0,5),isFullTrack:h.isFullTrack||!1}}async function analyzeLoopPoints(t){const e=t.getChannelData(0),o=t.sampleRate,n=e.length,i=Math.min(Math.floor(.5*o),Math.floor(n/2)),a=applyHannWindow(e.subarray(0,i)),s=applyHannWindow(e.subarray(n-i));let r=0,c=-1/0;for(let t=0;t<i;t++){let e=0;for(let o=0;o<i-t;o++)e+=a[o]*s[o+t];e>c&&(c=e,r=t)}return{loopStart:findZeroCrossing(e,0)/o,loopEnd:findZeroCrossing(e,n-i+r)/o,confidence:c/i,bestOffset:r,windowSize:i}}async function pitchBasedCompress(t,e){const o=t.sampleRate,n=Math.floor(t.length*e),i=(new(window.AudioContext||window.webkitAudioContext)).createBuffer(t.numberOfChannels,n,o);for(let o=0;o<t.numberOfChannels;o++){const a=t.getChannelData(o),s=i.getChannelData(o);for(let t=0;t<n;t++){const o=t/e,n=Math.floor(o),i=o-n;n+1<a.length?s[t]=a[n]*(1-i)+a[n+1]*i:s[t]=a[n]||0}}return i}async function tempoBasedCompress(t,e){return debugLog("Tempo-based compression not fully implemented - falling back to pitch-based"),await pitchBasedCompress(t,e)}class WaveformEditor{constructor(t,e,o){this.canvas=t,this.ctx=t.getContext("2d"),this.audioBuffer=e,this.analysis=o,this.loopStart=o.loopStart,this.loopEnd=o.loopEnd,this.isDragging=!1,this.dragTarget=null,this.setupInteraction(),this.draw()}setupInteraction(){this.canvas.addEventListener("mousedown",(t=>{const e=this.canvas.getBoundingClientRect(),o=t.clientX-e.left,n=o/this.canvas.width*this.audioBuffer.duration,i=this.loopStart/this.audioBuffer.duration*this.canvas.width,a=this.loopEnd/this.audioBuffer.duration*this.canvas.width;Math.abs(o-i)<10?(this.isDragging=!0,this.dragTarget="start"):Math.abs(o-a)<10?(this.isDragging=!0,this.dragTarget="end"):(Math.abs(o-i)<Math.abs(o-a)?this.loopStart=n:this.loopEnd=n,this.draw(),this.onLoopChange())})),this.canvas.addEventListener("mousemove",(t=>{if(this.isDragging){const e=this.canvas.getBoundingClientRect(),o=t.clientX-e.left,n=Math.max(0,Math.min(this.audioBuffer.duration,o/this.canvas.width*this.audioBuffer.duration));"start"===this.dragTarget?this.loopStart=Math.min(n,this.loopEnd-.1):"end"===this.dragTarget&&(this.loopEnd=Math.max(n,this.loopStart+.1)),this.draw(),this.onLoopChange()}})),this.canvas.addEventListener("mouseup",(()=>{this.isDragging=!1,this.dragTarget=null}))}draw(){const t=this.audioBuffer.getChannelData(0),e=Math.ceil(t.length/this.canvas.width);this.ctx.fillStyle="#000",this.ctx.fillRect(0,0,this.canvas.width,this.canvas.height),this.ctx.strokeStyle="#00ff00",this.ctx.lineWidth=1,this.ctx.beginPath();for(let o=0;o<this.canvas.width;o++){const n=t.slice(o*e,(o+1)*e),i=Math.min(...n),a=Math.max(...n),s=(i+1)*this.canvas.height/2,r=(a+1)*this.canvas.height/2;this.ctx.moveTo(o,s),this.ctx.lineTo(o,r)}this.ctx.stroke();const o=this.loopStart/this.audioBuffer.duration*this.canvas.width,n=this.loopEnd/this.audioBuffer.duration*this.canvas.width;this.ctx.fillStyle="rgba(0, 255, 0, 0.1)",this.ctx.fillRect(o,0,n-o,this.canvas.height),this.ctx.strokeStyle="#44ff44",this.ctx.lineWidth=2,this.ctx.beginPath(),this.ctx.moveTo(o,0),this.ctx.lineTo(o,this.canvas.height),this.ctx.stroke(),this.ctx.strokeStyle="#ff4444",this.ctx.beginPath(),this.ctx.moveTo(n,0),this.ctx.lineTo(n,this.canvas.height),this.ctx.stroke()}onLoopChange(){const t=new CustomEvent("loopChange",{detail:{loopStart:this.loopStart,loopEnd:this.loopEnd,duration:this.loopEnd-this.loopStart}});this.canvas.dispatchEvent(t)}}class LoopPlayer{constructor(t){this.audioBuffer=t,this.audioContext=new(window.AudioContext||window.webkitAudioContext),this.source=null,this.gainNode=null,this.isPlaying=!1,this.loopStart=0,this.loopEnd=t.duration,this.startTime=0}setLoopPoints(t,e){this.loopStart=t,this.loopEnd=e}async play(){if(this.stop(),"suspended"===this.audioContext.state)try{await this.audioContext.resume(),debugLog("Audio context resumed")}catch(t){return void console.error("Failed to resume audio context:",t)}this.source=this.audioContext.createBufferSource(),this.gainNode=this.audioContext.createGain(),this.source.buffer=this.audioBuffer,this.source.loop=!0,this.source.loopStart=this.loopStart,this.source.loopEnd=this.loopEnd,this.source.connect(this.gainNode),this.gainNode.connect(this.audioContext.destination),this.gainNode.gain.value=.5;try{debugLog(`Audio buffer duration: ${this.audioBuffer.duration}s`),debugLog(`Audio buffer sample rate: ${this.audioBuffer.sampleRate}Hz`),debugLog(`Loop start: ${this.loopStart}s, Loop end: ${this.loopEnd}s`),this.source.start(0,this.loopStart),this.isPlaying=!0,this.startTime=this.audioContext.currentTime,debugLog(`Playing loop: ${this.loopStart.toFixed(3)}s - ${this.loopEnd.toFixed(3)}s`),debugLog(`Audio context state: ${this.audioContext.state}`),setTimeout((()=>{debugLog(`Audio context time after 100ms: ${this.audioContext.currentTime}`)}),100)}catch(t){console.error("Failed to start audio:",t)}}stop(){this.source&&(this.source.stop(),this.source=null),this.isPlaying=!1}setVolume(t){this.gainNode&&(this.gainNode.gain.value=t)}}const version="1.0.2",name="Pleco Xa",author="Cameron Brooks";export{DEBUG_ENABLED,LoopPlayer,WaveformEditor,analyzeLoopPoints,analyzeWithReference,applyHannWindow,author,calculateBeatAlignment,computeFFT,computePeak,computeRMS,computeSpectralCentroid,computeSpectrum,computeZeroCrossingRate,createReferenceTemplate,debugLog,detectBPM,findAudioStart,findZeroCrossing,loopAnalysis,loadAudioBuffer,musicalLoopAnalysis,name,pitchBasedCompress,setDebug,tempoBasedCompress,version};
//# sourceMappingURL=pleco-xa.min.js.map
